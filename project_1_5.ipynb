{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd11da2a",
   "metadata": {},
   "source": [
    "# Project 1, Part 5, Data Visualization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b052db7c",
   "metadata": {},
   "source": [
    "# Included Modules and Packages\n",
    "\n",
    "Code cell containing your includes for modules and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a400eec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d954ac75",
   "metadata": {},
   "source": [
    "# Supporting code\n",
    "\n",
    "Code cells containing any supporting code, such as connecting to the database, any functions, etc.  Remember you can use any code from the labs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8fa124e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# function to run a select query and return rows in a pandas dataframe\n",
    "# pandas puts all numeric values from postgres to float\n",
    "# if it will fit in an integer, change it to integer\n",
    "#\n",
    "\n",
    "def my_select_query_pandas(query, rollback_before_flag, rollback_after_flag):\n",
    "    \"function to run a select query and return rows in a pandas dataframe\"\n",
    "    \n",
    "    if rollback_before_flag:\n",
    "        connection.rollback()\n",
    "    \n",
    "    df = pd.read_sql_query(query, connection)\n",
    "    \n",
    "    if rollback_after_flag:\n",
    "        connection.rollback()\n",
    "    \n",
    "    # fix the float columns that really should be integers\n",
    "    \n",
    "    for column in df:\n",
    "    \n",
    "        if df[column].dtype == \"float64\":\n",
    "\n",
    "            fraction_flag = False\n",
    "\n",
    "            for value in df[column].values:\n",
    "                \n",
    "                if not np.isnan(value):\n",
    "                    if value - math.floor(value) != 0:\n",
    "                        fraction_flag = True\n",
    "\n",
    "            if not fraction_flag:\n",
    "                df[column] = df[column].astype('Int64')\n",
    "    \n",
    "    return(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c00f0670",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = psycopg2.connect(\n",
    "    user = \"postgres\",\n",
    "    password = \"ucb\",\n",
    "    host = \"postgres\",\n",
    "    port = \"5432\",\n",
    "    database = \"postgres\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649af216",
   "metadata": {},
   "source": [
    "# 1.5 Example of a Data Visualization created using Python\n",
    "\n",
    "The data science team would like for you to create an example of a data visualization using Python from data in a Pandas dataframe containing data from an SQL query.\n",
    "\n",
    "Write 1 and only 1 query.  Note that the query may have as many subqueries, including \"with\" clauses, as you wish.  Any query of your choosing.  You can write a query from scratch.  You can use a query from a previous problem in this project.  You can use a query from the labs.  The idea is to come up with a query whose resulting data will make for an excellent quality data visualization. \n",
    "\n",
    "Ensure that when you check this Juptyer Notebook into GitHub that the query results in the Pandas dataframe are clearly visible in GitHub.  Note: When a query result has a large number of rows, Pandas will only display the first 5 rows, a row with ellipses, and the last 5 rows. This is ok.\n",
    "\n",
    "Once you have the data in a Pandas dataframe, you may write as much Python code and use as many code cells as you wish to produce the data visualization.\n",
    "\n",
    "You may only use Python modules that are currently installed in the Anaconda Docker container.  You may not install additional modules or any other software.\n",
    "\n",
    "All work must be done in Docker in your VM in AWS.  You may not use any external data visualization systems, such as Tableau, etc.\n",
    "\n",
    "You may use any code from the labs to pattern your code after, however for the data visualization, you cannot wholesale copy a data visualization from the labs.\n",
    "\n",
    "Ensure that it is properly titled, including titles for axes if present.\n",
    "\n",
    "Ensure that when you check this Juptyer Notebook into GitHub that the data visualization is clearly visible.  \n",
    "\n",
    "If you want to use Google Maps for your data visualization, this is fine, however, the image will not show up in GitHub.  So, just save the image to an image file, include it in the repo, and add a markdown cell to display the image file. Also with Google Maps, do NOT check gmap_api_key.txt into GitHub for security reasons.  If the grader needs to run it, they will supply their own gmap_api_key.txt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc31d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "rollback_before_flag = True\n",
    "rollback_after_flag = True\n",
    "\n",
    "query = \"\"\"\n",
    "\n",
    "with helper1 as (\n",
    "                  select zip, \n",
    "                         latitude, \n",
    "                         longitude,\n",
    "                         city,\n",
    "                         state,\n",
    "                         population as zip_population\n",
    "                  from zip_codes\n",
    "                  group by zip\n",
    "                ),\n",
    "    helper2 as  (\n",
    "                  select zip,\n",
    "                         count(*) as customer_population\n",
    "                  from customers\n",
    "                  group by zip\n",
    "                ),\n",
    "    helper3 as (\n",
    "                 select a.zip,\n",
    "                        a.customer_population,\n",
    "                        b.zip_population,\n",
    "                        b.latitude,\n",
    "                        b.longitude,\n",
    "                        b.city,\n",
    "                        b.state,\n",
    "                        customer_population * 100.0 / zip_population as percentage_customers_per_population_raw\n",
    "                 from helper2 as a\n",
    "                 join helper1 as b\n",
    "                 on a.zip = b.zip\n",
    "               )\n",
    "select zip,\n",
    "       city,\n",
    "       state,\n",
    "       latitude,\n",
    "       longitude,\n",
    "       round(percentage_customers_per_population_raw, 3) as percentage_customers_per_population\n",
    "from helper3\n",
    "order by percentage_customers_per_population_raw desc\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "df = my_select_query_pandas(query, rollback_before_flag, rollback_after_flag)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae747e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use as many code cells as you need to create and display your data visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a3c59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import gmaps\n",
    "import gmaps.geojson_geometries\n",
    "\n",
    "from geographiclib.geodesic import Geodesic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a27d8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('gmap_api_key.txt', 'r')\n",
    "my_api_key = f.read()\n",
    "f.close()\n",
    "\n",
    "gmaps.configure(api_key=my_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfda3dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = df['state'].unique()\n",
    "figs = []\n",
    "\n",
    "for index in range(0, len(states)):\n",
    "    df_state = df[df['state'] == states[index]]\n",
    "    center = (df_state['latitude'].mean(), df_state['longitude'].mean())\n",
    "    fig = gmaps.figure(center=center, zoom_level=10)\n",
    "    \n",
    "    locations = df_state[['latitude','longitude']]\n",
    "    weights = df_state[['percentage_customers_per_population']].to_numpy().reshape(len(df_state))\n",
    "    heatmap_layer = gmaps.heatmap_layer(locations=locations, weights=weights,point_radius=20)\n",
    "    fig.add_layer(heatmap_layer)\n",
    "    figs.append(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a193ba86",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf69086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "files = os.listdir()\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d1192d",
   "metadata": {},
   "source": [
    "<img src=https://github.com/mids-w205/project-1-vibhatna/blob/project/WA.png \\>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd35240",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3417559d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f0f9366",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bedaabd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aae0f385",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bb4f91b",
   "metadata": {},
   "source": [
    "![My Image Title](https://github.com/mids-w205/project-1-vibhatna/blob/project/WA.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5994e5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"files/WA.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce475af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"./WA.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffea6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://github.com/mids-w205/project-1-vibhatna/blob/project/WA.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c8de25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://en.wikipedia.org/wiki/University_of_California,_Berkeley#/media/File:CampanileMtTamalpiasSunset-original.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ae3da2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4a0ea3e",
   "metadata": {},
   "source": [
    "https://github.com/mids-w205/project-1-vibhatna/blob/project/WA.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48be0fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
